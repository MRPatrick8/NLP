{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MRPatrick8/NLP/blob/main/Word_and_PDF_extraction_Day3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with Word Documents and PDFs\n",
        "\n",
        "In the African continent, most documents are in word or PDF. For the data in the documents to be processed and used in AI, they need to be extracted. To do this, the data will be extracted to txt format.\n",
        "\n"
      ],
      "metadata": {
        "id": "-1LUjCesZBKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Package\n",
        "The package to be used in textract.\n",
        "\n",
        "To install the package, use the commands below\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "apt-get install python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr \\\n",
        "flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig\n",
        "\n",
        "pip install textract\n",
        "```\n",
        "\n",
        "The package supports a lot of formats including but not limmited:\n",
        "\n",
        "csv, doc, docx, epub,json, html,pdf, jpg, pptx, xls, xlsx, ogg \n",
        "\n"
      ],
      "metadata": {
        "id": "YhWTdFi4ebY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textract"
      ],
      "metadata": {
        "id": "rTyZY41XgWwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f023fc8f-11e1-4b11-8af3-748dd04f99f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textract in /usr/local/lib/python3.7/dist-packages (1.6.5)\n",
            "Requirement already satisfied: docx2txt~=0.8 in /usr/local/lib/python3.7/dist-packages (from textract) (0.8)\n",
            "Requirement already satisfied: six~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from textract) (1.12.0)\n",
            "Requirement already satisfied: beautifulsoup4~=4.8.0 in /usr/local/lib/python3.7/dist-packages (from textract) (4.8.2)\n",
            "Requirement already satisfied: extract-msg<=0.29.* in /usr/local/lib/python3.7/dist-packages (from textract) (0.28.7)\n",
            "Requirement already satisfied: SpeechRecognition~=3.8.1 in /usr/local/lib/python3.7/dist-packages (from textract) (3.8.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from textract) (3.0.4)\n",
            "Requirement already satisfied: xlrd~=1.2.0 in /usr/local/lib/python3.7/dist-packages (from textract) (1.2.0)\n",
            "Requirement already satisfied: argcomplete~=1.10.0 in /usr/local/lib/python3.7/dist-packages (from textract) (1.10.3)\n",
            "Requirement already satisfied: python-pptx~=0.6.18 in /usr/local/lib/python3.7/dist-packages (from textract) (0.6.21)\n",
            "Requirement already satisfied: pdfminer.six==20191110 in /usr/local/lib/python3.7/dist-packages (from textract) (20191110)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20191110->textract) (2.4.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20191110->textract) (3.15.0)\n",
            "Requirement already satisfied: soupsieve>=1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4~=4.8.0->textract) (2.3.2.post1)\n",
            "Requirement already satisfied: compressed-rtf>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from extract-msg<=0.29.*->textract) (1.0.6)\n",
            "Requirement already satisfied: tzlocal>=2.1 in /usr/local/lib/python3.7/dist-packages (from extract-msg<=0.29.*->textract) (4.2)\n",
            "Requirement already satisfied: olefile>=0.46 in /usr/local/lib/python3.7/dist-packages (from extract-msg<=0.29.*->textract) (0.46)\n",
            "Requirement already satisfied: imapclient==2.1.0 in /usr/local/lib/python3.7/dist-packages (from extract-msg<=0.29.*->textract) (2.1.0)\n",
            "Requirement already satisfied: ebcdic>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from extract-msg<=0.29.*->textract) (1.1.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract) (4.9.1)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract) (7.1.2)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.7/dist-packages (from python-pptx~=0.6.18->textract) (3.0.3)\n",
            "Requirement already satisfied: backports.zoneinfo in /usr/local/lib/python3.7/dist-packages (from tzlocal>=2.1->extract-msg<=0.29.*->textract) (0.2.1)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.7/dist-packages (from tzlocal>=2.1->extract-msg<=0.29.*->textract) (0.1.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.7/dist-packages (from pytz-deprecation-shim->tzlocal>=2.1->extract-msg<=0.29.*->textract) (2022.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx5KhiWzQVRQ"
      },
      "outputs": [],
      "source": [
        "# note: textract can extract images from images and videos\n",
        "import textract\n",
        "import os\n",
        "import PyPDF2 as pd2\n",
        "import glob #filtering only pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We wil first mount the google drive. This will give us acces to my drive folder where we can find files"
      ],
      "metadata": {
        "id": "4n65qBvfljQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqM410Q_hQBr",
        "outputId": "db8604d5-abdd-4281-80b4-d0968fa52cfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the ditection to where the files are located\n",
        "path = '/content/gdrive/MyDrive/NLP fellowship/assignments/day3/'\n",
        "os.chdir(\"/content\")\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaX6mmVBjdlw",
        "outputId": "17bc2665-2577-4ddf-b76a-2d576c30d55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOpdbqQj_dkJ",
        "outputId": "4e266e60-7555-4de1-bb7c-75e31f94fd79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code for extracting text pdf\n",
        "text = textract.process('Banana Bread.pdf')\n",
        "text = text.decode(\"utf-8\")\n",
        "type(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIZ2uzj4gLLP",
        "outputId": "637cf9b4-4957-4c03-d35f-0f9ac01fc511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path+'/text/textract_file.txt', 'w',  encoding='utf-8') as y:\n",
        "  for x in text.split('\\n'): #get every single line\n",
        "      if x != '':\n",
        "          y.write(x+' \\n')\n",
        "y"
      ],
      "metadata": {
        "id": "CPiyJT0GrNKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af9fd14-e3e8-491a-af0f-0aa76aaa2f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='/content/gdrive/MyDrive/NLP fellowship/assignments/day3//text/textract_file.txt' mode='w' encoding='utf-8'>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(path +\"/text\")\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2krIkgxQsW8m",
        "outputId": "87d5c73e-8c08-4c2d-b99d-ea5d5079f57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "textract_file.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting text with python package\n",
        "Docx files are writen in xml under the hood. If you unzip a docx file, you will find the components. The text is found in an xml file named document.xml. From the xml, you can extract text using beautifulsoup."
      ],
      "metadata": {
        "id": "xKU2FIS4vK4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup as bs\n",
        "content = []\n",
        "\n",
        "\n",
        "xml = 'document.xml'\n",
        "\n",
        "with open(xml, \"r\") as file:\n",
        "    # Read each line in the file, readlines() returns a list of lines\n",
        "    content = file.readlines()\n",
        "    # Combine the lines in the list into a string\n",
        "    content = \"\".join(content)\n",
        "    bs_content = bs(content, \"lxml\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(bs_content.prettify())\n"
      ],
      "metadata": {
        "id": "TZ1MqQnWcLXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IMRT_txBgDA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In class practicals\n",
        "From the xml, extract the text. The text should be put in a text file and have each sentence should be in its own line (No spaces between each line). e.g\n",
        "\n",
        "this is a book.\n",
        "\n",
        "the book looks nice.\n"
      ],
      "metadata": {
        "id": "KDcIOuhav13T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment\n",
        "You will be given 5 parliamentary proceedings, extract the text and put them in one txt file. Ski[p the last and first page. Steps:\n",
        "\n",
        "\n",
        "1.   Get a list of all the filepaths (through code)\n",
        "2.   open the file you want to write to(Note, remember to append the text)\n",
        "3.   Loop through every file\n",
        "4.   extract the text\n",
        "5.   write to the file (each sentence will be on its own line). There should be no spaces between lines (Note: remove empty lines)\n",
        "\n"
      ],
      "metadata": {
        "id": "ycw-85mfyM_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9pqkWqOYnta",
        "outputId": "4108f9f0-080c-4858-91a9-fc123853572a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.7/dist-packages (2.11.1)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from PyPDF2) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bCTEts8b7ZsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_path = '/content/gdrive/MyDrive/NLP fellowship/assignments/day3/PDF NLP parliamentary proceedings/'\n",
        "doc_dir=os.listdir(base_path)\n",
        "doc_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpohEeIirv7f",
        "outputId": "3e66257e-31d2-4c2d-b736-e4fa933c85e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hansard Report - Thursday, 13th October 2022 (P).pdf',\n",
              " 'Hansard Report - Wednesday, 12th October 2022 (P)_0.pdf',\n",
              " 'Hansard Report - Wednesday, 12th October 2022 (A).pdf',\n",
              " 'Hansard Report - Tuesday, 11th October 2022 (P).pdf',\n",
              " 'Hansard Report - Thursday 6th October 2022 (P).pdf',\n",
              " 'extracted.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fwgGWkZQuCBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this function is when you want to remove many middle pages\n",
        "def drop_pdf(path):\n",
        "  file_original= pd2.PdfFileReader(path)#open the original file containing all the pages-1\n",
        "  last_page=file_original.getNumPages()-1\n",
        "  # where to place the new \n",
        "  file_new=pd2.PdfFileWriter()\n",
        "  page_remove=[3,5,6]# all the pages that you want to remove\n",
        "  for page_number in range(1,last_page):\n",
        "    if page_number in page_remove:\n",
        "      pass\n",
        "    else:\n",
        "      page_content=file_original.getPage(page_number)\n",
        "      file_new.add_page(page_content)\n",
        "  return file_new\n"
      ],
      "metadata": {
        "id": "Q_DrBsG6sehl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_pdf(path):\n",
        "  # print('landed')\n",
        "  file_original= pd2.PdfFileReader(path)#open the original file containing all the pages-1\n",
        "  # print('reached here')\n",
        "  last_page=file_original.getNumPages()-1\n",
        "  # where to place the new \n",
        "  file_new=pd2.PdfFileWriter()\n",
        "  for page_number in range(1,last_page):\n",
        "    page_content=file_original.getPage(page_number)\n",
        "    file_new.add_page(page_content)\n",
        "  return file_new"
      ],
      "metadata": {
        "id": "2aY-wqs0yo4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test= drop_pdf(base_path+'Hansard Report - Thursday, 13th October 2022 (P).pdf')\n",
        "test.getNumPages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hZuDc-zzHlV",
        "outputId": "506714e2-7943-4a1e-be4a-0f73a728a5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "landed\n",
            "reached here\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save(name,file):\n",
        "  outputfilename='/content/gdrive/MyDrive/NLP fellowship/assignments/day3/new_content/'+name+ '.pdf' #construct the path and the filename\n",
        "  print(outputfilename)\n",
        "  with open (outputfilename, 'wb') as output:\n",
        "    file.write(output)\n"
      ],
      "metadata": {
        "id": "ZUHNfzzbznHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save('Test_2',test)"
      ],
      "metadata": {
        "id": "zYvCmyTK1z-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "U80RehlDAQO-",
        "outputId": "3c69fb64-4808-4f84-a1e3-8040a87beed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/MyDrive/NLP fellowship/assignments/day3/PDF NLP parliamentary proceedings/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for obj in doc_dir:\n",
        "  if obj.endswith(\".pdf\"):\n",
        "    # print(obj)\n",
        "    file_new=drop_pdf(base_path+obj)\n",
        "    save(obj,file_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IIBrwkb380c",
        "outputId": "e2257663-1b15-4361-ec18-39175beb52b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "landed\n",
            "reached here\n",
            "/content/gdrive/MyDrive/NLP fellowship/assignments/day3/new_content/Hansard Report - Thursday, 13th October 2022 (P).pdf.pdf\n",
            "landed\n",
            "reached here\n",
            "/content/gdrive/MyDrive/NLP fellowship/assignments/day3/new_content/Hansard Report - Wednesday, 12th October 2022 (P)_0.pdf.pdf\n",
            "landed\n",
            "reached here\n",
            "/content/gdrive/MyDrive/NLP fellowship/assignments/day3/new_content/Hansard Report - Wednesday, 12th October 2022 (A).pdf.pdf\n",
            "landed\n",
            "reached here\n",
            "/content/gdrive/MyDrive/NLP fellowship/assignments/day3/new_content/Hansard Report - Tuesday, 11th October 2022 (P).pdf.pdf\n",
            "landed\n",
            "reached here\n",
            "/content/gdrive/MyDrive/NLP fellowship/assignments/day3/new_content/Hansard Report - Thursday 6th October 2022 (P).pdf.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# py.pdf4 for removing the first and the last page\n",
        "# from PyPDF2 import PdfFileReader, PdfFileWriter\n",
        "\n",
        "# def split(path, name_of_split):\n",
        "#     pdf = PdfFileReader(path)\n",
        "#     for page in range(pdf.getNumPages()):\n",
        "#         pdf_writer = PdfFileWriter()\n",
        "#         pdf_writer.addPage(pdf.getPage(page))\n",
        "#         # print(pdf_writer)\n",
        "#         output = f'{name_of_split}{page}.pdf'\n",
        "#         with open(output, 'wb') as output_pdf:\n",
        "#             pdf_writer.write(output_pdf)\n",
        "#         print(pdf_writer)"
      ],
      "metadata": {
        "id": "tDgI7bgpgI7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1g1DYxwVzlqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path='/content/gdrive/MyDrive/NLP fellowship/assignments/day3/PDF NLP parliamentary proceedings/Hansard Report - Thursday 6th October 2022 (P).pdf'\n",
        "# name='doc1'\n",
        "# new_doc=split(path,name)\n",
        "# new_doc"
      ],
      "metadata": {
        "id": "hMR3UT2rhVYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# py.pdf4 for removing the first and the last page\n",
        "\n",
        "file_path=[]\n",
        "path='/content/gdrive/MyDrive/NLP fellowship/assignments/day3/new_content/'\n",
        "for single_file in os.listdir(path):\n",
        "  if single_file.endswith('.pdf'):\n",
        "    f_path=os.path.join(path + single_file)\n",
        "    file_path.append(f_path)\n",
        "file_path\n",
        "for single_path in file_path:\n",
        "  text =textract.process(single_path)\n",
        "  text = text.decode(\"utf-8\")\n",
        "\n",
        "with open('/content/gdrive/MyDrive/NLP fellowship/assignments/day3/extracted.txt','w+', encoding='utf-8') as f:\n",
        "  for x in text.split('\\n'):\n",
        "    if x!='':\n",
        "      f.write(x+ ' \\n')\n"
      ],
      "metadata": {
        "id": "KMAEBzOkqSEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d1C2yQn8S8Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Us60gRAiTMea"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}